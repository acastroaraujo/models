[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Models",
    "section": "",
    "text": "Preface\n\nRemember that all models are wrong; the practical question is how wrong do they have to be to not be useful.\n—Box & Draper (1987)\n\nTo do:\n\nnetwork formation (Page 2018, 122)\nfriendship paradoxes\nbroadcast, diffusion, contagion\n\n\n\n\n\nPage, Scott E. 2018. The Model Thinker: What You Need to Know to Make Data Work for You. Basic Books."
  },
  {
    "objectID": "intro.html#uses",
    "href": "intro.html#uses",
    "title": "1  Introduction",
    "section": "1.1 Uses",
    "text": "1.1 Uses\n[R] Reason. To identify conditions and deduce logical implications.\n\n…or REDCAPE\n\nWhile it’s true that the conclusions we derive depend on our assumptions, this doesn’t mean all models deliver tautologies. The logical implications of models are sometimes unexpected —e.g. Arrow’s impossibility theorem. Other times they will solve paradoxes —e.g. using causal models to solve Simpson’s paradox. And sometimes they will simply uncover mathematical relationships —e.g. prices and marginal costs.\nAbove all, logic reveals the conditionality of truths; they identify the conditions under which certain claims hold or don’t.\n\nCritics of formalism claim that models repackage what we already know, that they pour old wine into shiny mathematical bottles, that we do not need a model to know that two heads are better than one or that he who hesitates is lost. We can learn the value of commitment from reading of Odysseus tying himself to the mast. That criticism fails to recognize that inferences drawn from models take conditional forms: if \\(A\\) holds, then \\(B\\) follows. Lessons drawn from literature or proverbial advice from great thinkers often provide no conditions. If we try to lead our lives or manage others by unconditional truths, we find ourselves lost in a sea of opposite proverbs.\nPage (2018, 18)\n\nHow can we choose between the following list without knowing which conditions make them true?\n\n\n\n\n\n\n\nProverb\nOpposite\n\n\n\n\nTwo heads are better than one\nToo many cooks spoil the broth\n\n\nHe who hesitates is lost\nA stitch in time saves nine\n\n\nTie yourself to the mast\nKeep your options open\n\n\nThe perfect is the enemy of the good\nDo it well or not at all\n\n\nActions speak louder than words\nThe pen is mightier than the sword\n\n\n\n[E] Explain. To provide (testable) explanations for empirical phenomena.\nNote that models can also explain shape: e.g. network models of influence and contagion often produce S-shape curves.\n\nAs for the claim that models can explain anything: it is true, they can. However, a model-based explanation includes formal assumptions and explicit causal chains. Those assumptions and causal chains can be taken to data. A model that claims that high levels of criminal behavior can be explained by low probabilities of being caught can be tested.\nPage (2018, 19)\n\n[D] Design. To choose features of institutions, policies, and rules.\n[C] Communicate. Models improve communication by creating a common representation, thus enabling the transferring of ideas between different communities of inquiry.\n[A] Act. To guide policy choices and strategic actions.\n[P] Predict. To make numerical and categorical predictions of future and unknown phenomena. Note that prediction differs from explanation.\nFor example, deep-learning algorithms can predict many things with great accuracy, but they offer little in the way of explanation. On the other hand, some models can explain but have little predictive power. This is related to Elster’s (2015) discussion of the fact that we don’t know which “social mechanism” will be triggered in any given situation.\n[E] Explore. To investigate possibilities and hypotheticals —i.e., the “alternative reality approach”."
  },
  {
    "objectID": "intro.html#human-behavior",
    "href": "intro.html#human-behavior",
    "title": "1  Introduction",
    "section": "1.2 Human Behavior",
    "text": "1.2 Human Behavior\nPage (2018) notes that modeling human behavior is challenging because people share six characteristics: we are diverse; we are socially influenced; we are error-prone; we are purposive; we learn; and we have agency.\n\nEach of this six characteristics are potential model features. If we include a feature, we must decide how much of it to include. How diverse do we make our actors? How much social influence do we include? Do people learn from others? How do we define objectives? How much agency do people possess?\nPage (2018, 47)\n\nFor example, to tackle diversity we sometimes assume that behavioral diversity cancels out. And this will only happen if the actions people take are independent (i.e. models of normal distributions).\nThat being said, Page (2018) divides his repertoire of models according to whether we believe humans to follow a logic of consequence (i.e., rational decision-makers) or they follow a logic of appropriateness (i.e., rule-followers).\n\n1.2.1 Rational-choice models\nAn agent is rational if she makes choices towards fulfilling a goal, making the most efficient use of resources.\n\nAn individual’s preferences are represented by a mathematical utility or payoff function defined over a set of possible actions. The individual chooses the action that maximizes the function’s value. In a game, that choice may require beliefs about the actions of other players.\nPage (2018, 48)\n\nIn assuming a utility function, we give preferences a coherency that may not exist. These preferences must satisfy certain axioms in order to be representable by a utility function: completeness, transitivity, independence, and continuity.\nSuppose we have a choice set \\(X = \\{x_1, x_2, \\dots, x_n\\}\\) that contains all available alternatives (e.g. stuff to buy, decisions to make).\n\nCompleteness: all pairs of alternatives can be compared.\nTransitivity: a logical order can be established among them: if \\(x_1 \\succeq x_2\\) and \\(x_2 \\succeq x_3\\), then \\(x_1 \\succeq x_3\\).\nIndependence of irrelevant alternatives.\nContinuity: if we have \\(x_1 \\succeq x_2 \\succeq x_3\\), then there exists a probability \\(p\\) such that \\(x_2 = p\\ x_1 + (1-p) x_3\\).\n\nPeople will violate this axioms under any number of circumstances, leading to a widespread skepticism of rational-actor models. Page responds to these criticisms with four arguments, depicted in Table 1.1.\n\n\nTable 1.1: Arguments for Rational Choice\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n“As if”\nIntelligent rule-based behavior may be indistinguishable from optimal or near-optimal behavior\n\n\nLearning\nIn situations that are repeated, people should approach optimal behavior\n\n\nLarge stakes\nOn important decisions, people gather information and think slowly\n\n\nUniqueness\nOptimal behavior is often unique, making the model testable/ tractable\n\n\nConsistency\nOptimal behavior creates a consistent model. If people learn the model, they will not change their behavior\n\n\nBenchmark\nOptimal behavior provides a benchmark as an upper bound on people’s cognitive abilities\n\n\n\n\nThe consistency argument is related to “Lucas’ critique”, discussed near the end. Basically, any model that doesn’t predict optimal behavior will fail to make long-term predictions when people have something to gain by optimizing their behavior.\nAlso, numerous studies on “heuristics and cognitive bias” (e.g. loss aversion and hyperbolic discounting) have shown systematic deviations from rational choice.\nThese considerations aside, Page argues that we should always be open to the possibility that rational-actor models will not solve the problem at hand, and that we should privilege other models instead.\n\n\n1.2.2 Rule-based models\nWhereas optimization-based models assume an underlying utility or payoff function that people maximize, rule-based models assume specific behaviors. Many people equate optimization-based models with mathematics and rule-based models with computation, but this distinction is not very clean.\n\nFixed rules. A fixed rule applies the same algorithm (or decision making protocol) at all times. This will provide a lower bound on people’s cognitive abilities. For example, “zero intelligence” is sometimes used as a fixed rule in markets: zero-intelligence traders accept any offer that produces a payoff. Remarkably, encoding this rule in a computer model results in nearly efficient outcomes.\nAdaptive rules. An adaptive rule switches among a set of behaviors, evolves new behaviors, or copies the behaviors of others in order to improve a payoff. Thus, adaptive rules require a utility or payoff function. People like Gerd Gigerenzer argue that people tend toward simple and effective rules within any given situation, and that if that’s what people do, then we should model them this way.\n\nNote that rule-based models make no explicit assumption about rationality, but adaptive-rule models exhibit “ecological rationality”—i.e., better rules eventually predominate.\nFinally, note that some rule-based behaviors approximate rational choice. For example, “buy low, sell high” is a very simple heuristic that will consistently lead to profit in a market economy. Rules like these might be held consciously or unconsciously.\nHow smart should we make the actors in our models?\nIt depends on what type of outcome is produced by the model. We have four options: equilibrium, cycles, randomness, or complexity. If the model produces randomness at an aggregate level, then it’s safe to say that individuals probably can’t learn anything —i.e. they can’t choose optimally. The models that produce cycles or equilibria, on the other hand, create a stationary environment in which we expect people to learn.\nNotice that if adaptive rules produce an equilibrium, then the equilibrium should be consistent with behavior by optimizing agents. Otherwise, optimal behavior will be an unrealistic assumption in complex situations.\nThe Lucas critique\nIf people learn, then we cannot rely on past data to predict outcomes under a policy change. This insight is a variant of Campbell’s law, which states that people respond to any measure in ways that render it less effective. Thus, models must take into account the fact that people respond to policy and environmental changes.\n\n\n\n\nElster, Jon. 2015. Explaining Social Behavior: More Nuts and Bolts for the Social Sciences. Cambridge University Press.\n\n\nPage, Scott E. 2018. The Model Thinker: What You Need to Know to Make Data Work for You. Basic Books."
  },
  {
    "objectID": "sim-00-intro.html",
    "href": "sim-00-intro.html",
    "title": "Simulation",
    "section": "",
    "text": "Some remarks"
  },
  {
    "objectID": "net-00-intro.html#introduction",
    "href": "net-00-intro.html#introduction",
    "title": "Network Models",
    "section": "Introduction",
    "text": "Introduction\n\nAny model we construct, be it of a market, the spread of a disease, or the transmission of information, can be enriched by embedding the actors in a network.\nPage (2018, 117)\n\nA network is a representation of a system that contains discrete, interconnected elements. The elements are represented by nodes (or vertices), and the interconnections are represented by edges (or ties).\nEdges may have attributes like distance or monetary transactions—i.e., weights. They may also be directed or undirected, depending on whether the relationships they represent are asymmetric or symmetric.\nMany real-world problems can be solved using graph algorithms. For example, Dijkstra’s shortest path algorithm is an efficient way to find the shortest path from a node to all other nodes in a graph.\nFormal Presentation\nA graph is a mathematical object that consists of a set of \\(V\\) of vertices (or nodes) and a multiset \\(E\\) of pairs of elements in \\(V\\). It encodes relational information (or connections).\n\nA weighted graph will contain another set of elements associated to each pair of nodes in \\(E\\).\n\n\\[\nG = \\{V, E\\}\n\\]\n\nA multiset is an set in which elements are allowed to appear more than once. For example: \\(\\{a, a, b, c, c, c\\}\\).\n\nWhen two nodes \\(a\\) and \\(b\\) are connected, \\(\\{a, b\\} \\in E\\), we call them adjacent.\nWe can also represent a graph as an adjacency matrix \\(\\mathbf{M}\\) such that each entry \\(m_{ij}\\) is zero when \\(\\{i, j\\} \\not \\in E\\).\n\\[\nm_{ij} = \\begin{cases}\n1 &\\text{if } (v_i, v_j) \\in E \\\\\n0 &\\text{if } (v_i, v_j) \\not \\in E\n\\end{cases}\n\\]\n\n\nCode\n# Adj. Matrix\nset.seed(1111)\nn <- 5\nM <- array(\n  data = sample(1:0, size = n*n, replace = TRUE), \n  dim = c(n, n),\n  dimnames = list(letters[1:n], letters[1:n])\n)\n\ndiag(M) <- 0\n\nknitr::kable(M) |> \n  kableExtra::kable_styling()\n# Graph\n\nlibrary(igraph)\nlibrary(ggraph)\n\nnet <- igraph::graph_from_adjacency_matrix(M, mode = \"directed\") \n\nnet |> \n  ggraph() + \n  geom_node_text(aes(label = name), color = \"steelblue1\", size = 8) + \n  geom_edge_fan(\n    arrow = arrow(length = unit(0.25, \"cm\")),\n    end_cap = circle(.5, \"cm\"),\n    start_cap = circle(.5, \"cm\"),\n    colour = \"steelblue1\"\n  ) +\n  theme_void()\n\n\n\n\n\n\n \n  \n      \n    a \n    b \n    c \n    d \n    e \n  \n \n\n  \n    a \n    0 \n    1 \n    1 \n    1 \n    1 \n  \n  \n    b \n    0 \n    0 \n    0 \n    0 \n    1 \n  \n  \n    c \n    0 \n    0 \n    0 \n    0 \n    1 \n  \n  \n    d \n    0 \n    0 \n    1 \n    0 \n    1 \n  \n  \n    e \n    0 \n    1 \n    1 \n    0 \n    0 \n  \n\n\n\n\n\n\n\n\n\n\nThe matrix representation is better suited for calculating all sorts of network statistics. In what follows, we will refer to these objects as M and net respectively."
  },
  {
    "objectID": "net-00-intro.html#network-statistics",
    "href": "net-00-intro.html#network-statistics",
    "title": "Network Models",
    "section": "Network Statistics",
    "text": "Network Statistics\n\nNodes\nDegree\nThis measure captures the number of ties for each node. When we look at directed graphs, we need to distinguish between two types of degrees:\n\noutdegree: the number of ties sent from node \\(i\\)\n\nrowSums(M)\n\na b c d e \n4 1 1 2 2 \n\nigraph::degree(net, mode = \"out\")\n\na b c d e \n4 1 1 2 2 \n\n\nindegree: the number of ties received by node \\(i\\)\n\ncolSums(M)\n\na b c d e \n0 2 3 1 4 \n\nigraph::degree(net, mode = \"in\")\n\na b c d e \n0 2 3 1 4 \n\n\n\nThe degree distribution tells us if some nodes are more connected than others. Social networks usually have more equal distributions than networks connecting websites or citations among documents, all of which have long tails.\n\nA power-law network is a network whose degree distribution follows a “power law.”\n\nNeighbors\nThe set of nodes in \\(u\\)’s neighborhood is usually depicted as \\(N_u\\) and \\(|N_u|\\) represents the number of nodes in that neighborhood.\n\nigraph::neighbors(net, v = \"a\")\n\n+ 4/5 vertices, named, from 4ef57b9:\n[1] b c d e\n\nigraph::neighborhood(net)\n\n[[1]]\n+ 5/5 vertices, named, from 4ef57b9:\n[1] a b c d e\n\n[[2]]\n+ 3/5 vertices, named, from 4ef57b9:\n[1] b a e\n\n[[3]]\n+ 4/5 vertices, named, from 4ef57b9:\n[1] c a d e\n\n[[4]]\n+ 4/5 vertices, named, from 4ef57b9:\n[1] d a c e\n\n[[5]]\n+ 5/5 vertices, named, from 4ef57b9:\n[1] e a b c d\n\n\nNote that the igraph::neighborhood() function includes \\(u\\) among \\(N_u\\).\nLocal Clustering Coefficient\nThe clustering coefficient of \\(u\\) is the percentage of \\(u\\)’s pairs of neighbors that are also connected by a tie—e.g., if \\(u\\) has a neighborhood of size 10, then it has \\({10 \\choose 2} = 45\\) pairs of friends; if 15 of those 45 pairs are themselves connected, then \\(u\\)’s clustering coefficient equal \\(\\frac{1}{3}\\).\nI don’t know about the following equations…\n\nFrequency Interpretation:\n\\[\nC_u = \\frac{| \\{{v, w \\in N_u \\mid (v, w) \\in E} \\}|}{|N_u| \\times (|N_u| - 1)}\n\\]\nProbability Interpretation:\n\nBetweenness\nBetweennnes. The number of paths of minimal length connecting two other nodes that pass through one node.\nThe average length between nodes gets shorter as we add more edges to a graph.\n\n\nNetwork\nDensity\nThis measure captures the total number of edges (or ties) in the network, divided by the total number of possible edges.\nGetting to the total number of possible edges requires a little bit of combinatorics:\n\nPossible edges in an undirected network\n\\[\n{n \\choose 2} = \\frac{n!}{(n - 2)! 2!} = \\frac{n (n-1)}{2}\n\\]\nPossible edges in a directed network\n\\[\n\\underbrace{P(n, 2)}_\\text{permutation} = \\frac{n!}{(n-2)!} = n(n-1)\n\\]\nPossible edges in an undirected network (loops allowed)\n\\[\n{n \\choose 2} + \\underbrace{n}_\\text{diagonal} = \\frac{n (n-1)}{2} + n\n\\]\nPossible edges in a directed network (loops allowed)\n\\[\nP(n, 2) + \\underbrace{n}_\\text{diagonal} = n(n-1) + n\n\\]\n\nThus, the density of a graph \\(G = \\{V, E\\}\\) is simply:\n\\[\n\\text{density}(G_n) = \\frac{|E|}{|V| \\cdot (|V| - 1)}\n\\]\nHere is how we perform such a calculation:\n\nn_nodes <- igraph::gorder(net)\nn_edges <- igraph::gsize(net)\nn_possible_edges <- n_nodes * (n_nodes - 1)\n## density\nn_edges / n_possible_edges\n\n[1] 0.5\n\nigraph::edge_density(net)\n\n[1] 0.5\n\n\n\n\nFlow\nWalks\nAny sequence of edges that connect \\(i\\) to \\(j\\). For example, the following sequence is a walk of length 4 from \\(i\\) to \\(j\\):\n\\[\ni \\to k \\to l \\to k \\to j\n\\]\nBy raising the adjacency matrix to the nth power, we get the number of walks of length \\(n\\) between all \\(i,j\\) pairs.\n\nwalks <- function(M, n) {\n  stopifnot(n >= 0, nrow(M) == ncol(M))\n  if (n == 0) {\n   diag(nrow(M))\n  } else{\n   Reduce(`%*%`, rep(list(M), n)) \n  }\n}\n\n## number of walks of length 3\nwalks(M, 3)\n\n  a b c d e\na 0 3 3 0 3\nb 0 0 0 0 2\nc 0 0 0 0 2\nd 0 1 1 0 2\ne 0 2 2 0 0\n\nM %*% M %*% M \n\n  a b c d e\na 0 3 3 0 3\nb 0 0 0 0 2\nc 0 0 0 0 2\nd 0 1 1 0 2\ne 0 2 2 0 0\n\n\nPaths\nPath length. The minimum number of edges that must be traversed to get from one node to another.\nAny sequence of edges that connect \\(i\\) to \\(j\\), where a path is not allowed to revisit the same node twice (unlike walks). We use the igraph::distances() function to get the shortest path (or distance) between every node. The mode = \"out\" argument says we want the distance from \\(i\\) to \\(j\\), which is what we typically want.\n\ndist_mat <- igraph::distances(net, mode = \"out\")\ndist_mat\n\n    a b c   d e\na   0 1 1   1 1\nb Inf 0 2 Inf 1\nc Inf 2 0 Inf 1\nd Inf 2 1   0 1\ne Inf 1 1 Inf 0\n\n\nHere, we can see there is at least one path of length 2 between \\(c\\) and \\(b\\). Note that Inf means that \\(i\\) cannot reach \\(j\\) through any path. To get the specific paths connecting \\(i\\) to \\(j\\) we can use the all_shortest_paths() function.\n\nigraph::all_shortest_paths(net, from = \"d\", to = \"b\", mode = \"out\")\n\n$res\n$res[[1]]\n+ 3/5 vertices, named, from 4ef57b9:\n[1] d e b\n\n\n$nrgeo\n[1] 0 1 1 1 1\n\n\n\nnrgeo is the resultant vector of values from Djikstra’s algorithm which is used to find the shortest paths.\n\nIt’s often the case that we want to summarize the distance over all \\(i,j\\) pairs. We can calculate this using the distance matrix calculated above.\n\ndiag(dist_mat) <- NA # remove the elements in the diagonal\nmean(dist_mat[dist_mat != Inf], na.rm = TRUE) # # remove Inf values\n\n[1] 1.230769\n\n\nThus, we see that nodes are (on average) separated by paths of length 1.23 (excluding pairs that cannot reach each other).\nNote that we also remove all Inf values, which means we excluded all unreachable pairs. This is a common approach but also throws out information on all cases where \\(i\\) cannot reach \\(j\\).\nCloseness\nAlternatively, we can use the “closeness” measure if we have unreachable pairs. Closeness is based on the inverse of the distance matrix. By inverting the distance matrix, all Inf values are turned into \\(0\\)s and thus can be included in the mean calculation. The inverse of the distance matrix has the opposite interpretation as above, showing show how “close” node \\(i\\) is to node \\(j\\). The disadvantage of a closeness measure is that the interpretation is not as intuitive as with distance.\n\nclose_mat <- 1 / dist_mat \nclose_mat\n\n   a   b   c  d  e\na NA 1.0 1.0  1  1\nb  0  NA 0.5  0  1\nc  0 0.5  NA  0  1\nd  0 0.5 1.0 NA  1\ne  0 1.0 1.0  0 NA\n\nmean(close_mat, na.rm = TRUE)\n\n[1] 0.575\n\n\nNote that the “mean closeness” will not mirror the “mean distance” because we have now included all unreachable pairs.\nReachability\nThis measure captures whether node \\(i\\) can reach node \\(j\\) through any path. This can be calculated directly from the distance matrix. Node \\(i\\) can reach node \\(j\\) if the distance between them is less than Inf.\n\nreach_mat <- ifelse(dist_mat == Inf, 0, 1)\nreach_mat\n\n   a  b  c  d  e\na NA  1  1  1  1\nb  0 NA  1  0  1\nc  0  1 NA  0  1\nd  0  1  1 NA  1\ne  0  1  1  0 NA\n\n\nDiameter\nWe can also use the distance matrix to calculate diameter, showing the longest geodesic (or distance) between any two nodes in the network. Diameter thus takes all of the shortest paths between nodes (i.e., distance) and calculates the longest path among that set.\n\nmax(dist_mat[dist_mat != Inf], na.rm = TRUE)\n\n[1] 2\n\nigraph::diameter(net)\n\n[1] 2\n\n\n\nLike all models, networks are just abstractions.\nMcFarland et al. (2023) suggest we view network models in terms of two theoretical perspectives and two explanatory purposes, as depicted in Table 1. This is not a definitive statement of network research, but rather a heuristic tool.\n\n\nTable 1: Networks and Research Agendas\n\n\n\n\n\n\n\nPerspective\nNetworks as Cause\nNetworks as Consequence\n\n\n\n\n\nConnectionist\n\nNetworks as pipes\n\n\nDiffusion\nPeer influence\nSocial capital\nSocial integration\nPeer selection\nSegregation\n\n\n\nPositional\n\nNetworks as roles\n\n\nPopularity effects\nRole behavior\nNetwork constraing\nExchange patterns\nNetwork stability\nCareer paths\n\n\n\n\nThis distinctions are important. For example, the average path length between nodes in a graph is correlated with information loss because “information that passes through several people is more likely to suffer distortion than information passed between only two people” (Page 2018, 119). Similarly, high betweenness scores in social networks imply that the individual will hold more information or wield more power. However, none of these interpretations make no sense when we consider networks-as-roles.\nNote. The field of network analysis has a long interdisciplinary history in sociology, anthropology, psychology, and mathematics. Due to advances in computation—and the creation of the Internet—the ability to collect network information has greatly increased and we’re starting to see the rise of a much broader (but fragmented) field of network science. Computers scientists (e.g., Kleinberg), physicists (e.g., Barabassi, Newman), and statisticians (e.g., Snijders, Hancock) have become important new players in the field. As a result, the field has begun to lack a clear integration of theories and methods.\nSEE PAGE 44 FOR FOUR THINGS\nsimilarities, relations, interactions, flows\nMemberships, in which nodes are located in the same regions in physical and social space (e.g., same neighborhoods, same department, or same club). Relations, in which nodes operate within a system of roles (e.g., father of, friend of, or teacher of) and have cognitive or affective orientations toward one another. Interactions, in which concrete interactions occur between nodes (e.g., advice, romance, or bullying). Flows, in which nodes transfer some material or cultural object, goods, information, or influence (e.g., ideas, beliefs, practices).\n\n\n\n\nMcFarland, Daniel A., Jeffrey A. Smith, James Moody, and Craig M. Rawlings. 2023. Network Analysis: Integrating Social Network Theory, Method, and Application with r. Structural Analysis in the Social Sciences. Cambridge: Cambridge University Press. https://www.cambridge.org/core/books/network-analysis/C9202FD5420BE99225FEED4B6214DBB7.\n\n\nPage, Scott E. 2018. The Model Thinker: What You Need to Know to Make Data Work for You. Basic Books."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Elster, Jon. 2015. Explaining Social Behavior: More Nuts and Bolts\nfor the Social Sciences. Cambridge University Press.\n\n\nMcFarland, Daniel A., Jeffrey A. Smith, James Moody, and Craig M.\nRawlings. 2023. Network Analysis: Integrating Social Network Theory,\nMethod, and Application with r. Structural Analysis in the Social\nSciences. Cambridge: Cambridge University Press. https://www.cambridge.org/core/books/network-analysis/C9202FD5420BE99225FEED4B6214DBB7.\n\n\nPage, Scott E. 2018. The Model Thinker: What You Need to Know to\nMake Data Work for You. Basic Books."
  }
]