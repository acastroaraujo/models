[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Models",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html#uses",
    "href": "intro.html#uses",
    "title": "1  Introduction",
    "section": "1.1 Uses",
    "text": "1.1 Uses\n[R] Reason. To identify conditions and deduce logical implications.\n\n…or REDCAPE\n\nWhile it’s true that the conclusions we derive depend on our assumptions, this doesn’t mean all models deliver tautologies. The logical implications of models are sometimes unexpected —e.g. Arrow’s impossibility theorem. Other times they will solve paradoxes —e.g. using causal models to solve Simpson’s paradox. And sometimes they will simply uncover mathematical relationships —e.g. prices and marginal costs.\nAbove all, logic reveals the conditionality of truths; they identify the conditions under which certain claims hold or don’t.\n\nCritics of formalism claim that models repackage what we already know, that they pour old wine into shiny mathematical bottles, that we do not need a model to know that two heads are better than one or that he who hesitates is lost. We can learn the value of commitment from reading of Odysseus tying himself to the mast. That criticism fails to recognize that inferences drawn from models take conditional forms: if \\(A\\) holds, then \\(B\\) follows. Lessons drawn from literature or proverbial advice from great thinkers often provide no conditions. If we try to lead our lives or manage others by unconditional truths, we find ourselves lost in a sea of opposite proverbs.\nPage (2018, 18)\n\nHow can we choose between the following list without knowing which conditions make them true?\n\n\n\n\n\n\n\nProverb\nOpposite\n\n\n\n\nTwo heads are better than one\nToo many cooks spoil the broth\n\n\nHe who hesitates is lost\nA stitch in time saves nine\n\n\nTie yourself to the mast\nKeep your options open\n\n\nThe perfect is the enemy of the good\nDo it well or not at all\n\n\nActions speak louder than words\nThe pen is mightier than the sword\n\n\n\n[E] Explain. To provide (testable) explanations for empirical phenomena.\nNote that models can also explain shape: e.g. network models of influence and contagion often produce S-shape curves.\n\nAs for the claim that models can explain anything: it is true, they can. However, a model-based explanation includes formal assumptions and explicit causal chains. Those assumptions and causal chains can be taken to data. A model that claims that high levels of criminal behavior can be explained by low probabilities of being caught can be tested.\nPage (2018, 19)\n\n[D] Design. To choose features of institutions, policies, and rules.\n[C] Communicate. Models improve communication by creating a common representation, thus enabling the transferring of ideas between different communities of inquiry.\n[A] Act. To guide policy choices and strategic actions.\n[P] Predict. To make numerical and categorical predictions of future and unknown phenomena. Note that prediction differs from explanation.\nFor example, deep-learning algorithms can predict many things with great accuracy, but they offer little in the way of explanation. On the other hand, some models can explain but have little predictive power. This is related to Elster’s (2015) discussion of the fact that we don’t know which “social mechanism” will be triggered in any given situation.\n[E] Explore. To investigate possibilities and hypotheticals —i.e., the “alternative reality approach”."
  },
  {
    "objectID": "intro.html#human-behavior",
    "href": "intro.html#human-behavior",
    "title": "1  Introduction",
    "section": "1.2 Human Behavior",
    "text": "1.2 Human Behavior\nPage (2018) notes that modeling human behavior is challenging because people share six characteristics: we are diverse; we are socially influenced; we are error-prone; we are purposive; we learn; and we have agency.\n\nEach of this six characteristics are potential model features. If we include a feature, we must decide how much of it to include. How diverse do we make our actors? How much social influence do we include? Do people learn from others? How do we define objectives? How much agency do people possess?\nPage (2018, 47)\n\nFor example, to tackle diversity we sometimes assume that behavioral diversity cancels out. And this will only happen if the actions people take are independent (i.e. models of normal distributions).\nThat being said, Page (2018) divides his repertoire of models according to whether we believe humans to follow a logic of consequence (i.e., rational decision-makers) or they follow a logic of appropriateness (i.e., rule-followers).\n\n1.2.1 Rational-choice models\nAn agent is rational if she makes choices towards fulfilling a goal, making the most efficient use of resources.\n\nAn individual’s preferences are represented by a mathematical utility or payoff function defined over a set of possible actions. The individual chooses the action that maximizes the function’s value. In a game, that choice may require beliefs about the actions of other players.\nPage (2018, 48)\n\nIn assuming a utility function, we give preferences a coherency that may not exist. These preferences must satisfy certain axioms in order to be representable by a utility function: completeness, transitivity, independence, and continuity.\nSuppose we have a choice set \\(X = \\{x_1, x_2, \\dots, x_n\\}\\) that contains all available alternatives (e.g. stuff to buy, decisions to make).\n\nCompleteness: all pairs of alternatives can be compared.\nTransitivity: a logical order can be established among them: if \\(x_1 \\succeq x_2\\) and \\(x_2 \\succeq x_3\\), then \\(x_1 \\succeq x_3\\).\nIndependence of irrelevant alternatives.\nContinuity: if we have \\(x_1 \\succeq x_2 \\succeq x_3\\), then there exists a probability \\(p\\) such that \\(x_2 = p\\ x_1 + (1-p) x_3\\).\n\nPeople will violate this axioms under any number of circumstances, leading to a widespread skepticism of rational-actor models. Page responds to these criticisms with four arguments, depicted in Table 1.1.\n\n\nTable 1.1: Arguments for Rational Choice\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\n“As if”\nIntelligent rule-based behavior may be indistinguishable from optimal or near-optimal behavior\n\n\nLearning\nIn situations that are repeated, people should approach optimal behavior\n\n\nLarge stakes\nOn important decisions, people gather information and think slowly\n\n\nUniqueness\nOptimal behavior is often unique, making the model testable/ tractable\n\n\nConsistency\nOptimal behavior creates a consistent model. If people learn the model, they will not change their behavior\n\n\nBenchmark\nOptimal behavior provides a benchmark as an upper bound on people’s cognitive abilities\n\n\n\n\nThe consistency argument is related to “Lucas’ critique”, discussed near the end. Basically, any model that doesn’t predict optimal behavior will fail to make long-term predictions when people have something to gain by optimizing their behavior.\nAlso, numerous studies on “heuristics and cognitive bias” (e.g. loss aversion and hyperbolic discounting) have shown systematic deviations from rational choice.\nThese considerations aside, Page argues that we should always be open to the possibility that rational-actor models will not solve the problem at hand, and that we should privilege other models instead.\n\n\n1.2.2 Rule-based models\nWhereas optimization-based models assume an underlying utility or payoff function that people maximize, rule-based models assume specific behaviors. Many people equate optimization-based models with mathematics and rule-based models with computation, but this distinction is not very clean.\n\nFixed rules. A fixed rule applies the same algorithm (or decision making protocol) at all times. This will provide a lower bound on people’s cognitive abilities. For example, “zero intelligence” is sometimes used as a fixed rule in markets: zero-intelligence traders accept any offer that produces a payoff. Remarkably, encoding this rule in a computer model results in nearly efficient outcomes.\nAdaptive rules. An adaptive rule switches among a set of behaviors, evolves new behaviors, or copies the behaviors of others in order to improve a payoff. Thus, adaptive rules require a utility or payoff function. People like Gerd Gigerenzer argue that people tend toward simple and effective rules within any given situation, and that if that’s what people do, then we should model them this way.\n\nNote that rule-based models make no explicit assumption about rationality, but adaptive-rule models exhibit “ecological rationality”—i.e., better rules eventually predominate.\nFinally, note that some rule-based behaviors approximate rational choice. For example, “buy low, sell high” is a very simple heuristic that will consistently lead to profit in a market economy. Rules like these might be held consciously or unconsciously.\nHow smart should we make the actors in our models?\nIt depends on what type of outcome is produced by the model. We have four options: equilibrium, cycles, randomness, or complexity. If the model produces randomness at an aggregate level, then it’s safe to say that individuals probably can’t learn anything —i.e. they can’t choose optimally. The models that produce cycles or equilibria, on the other hand, create a stationary environment in which we expect people to learn.\nNotice that if adaptive rules produce an equilibrium, then the equilibrium should be consistent with behavior by optimizing agents. Otherwise, optimal behavior will be an unrealistic assumption in complex situations.\nThe Lucas critique\nIf people learn, then we cannot rely on past data to predict outcomes under a policy change. This insight is a variant of Campbell’s law, which states that people respond to any measure in ways that render it less effective. Thus, models must take into account the fact that people respond to policy and environmental changes.\n\n\n\n\nElster, Jon. 2015. Explaining Social Behavior: More Nuts and Bolts for the Social Sciences. Cambridge University Press.\n\n\nPage, Scott E. 2018. The Model Thinker: What You Need to Know to Make Data Work for You. Basic Books."
  },
  {
    "objectID": "sim-00-intro.html",
    "href": "sim-00-intro.html",
    "title": "Simulation",
    "section": "",
    "text": "Some remarks"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Elster, Jon. 2015. Explaining Social Behavior: More Nuts and Bolts\nfor the Social Sciences. Cambridge University Press.\n\n\nPage, Scott E. 2018. The Model Thinker: What You Need to Know to\nMake Data Work for You. Basic Books."
  }
]